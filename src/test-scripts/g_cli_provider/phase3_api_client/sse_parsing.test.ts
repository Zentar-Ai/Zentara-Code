/**
 * Phase 3: SSE Parsing Tests
 * Tests for g-cli Server-Sent Events parsing following TDD approach
 *
 * Run with: npx vitest run src/test-scripts/gemini_cli_provider/phase3_api_client/sse_parsing.test.ts
 */

import { describe, it, expect, beforeEach, vi, afterEach } from "vitest"

// Mock ReadableStream for SSE testing
global.ReadableStream = class MockReadableStream {
	constructor(source: any) {
		this.source = source
	}
	source: any

	getReader() {
		return {
			read: vi.fn(),
			releaseLock: vi.fn(),
		}
	}
}

describe("Phase 3: SSE Parsing", () => {
	let apiClient: any
	const mockOptions = {
		accessToken: "test-access-token",
		projectId: "test-project-123",
	}

	beforeEach(() => {
		vi.clearAllMocks()

		try {
			const { GCliApiClient } = require("../../../../src/api/providers/g-cli/api-client")
			apiClient = new GCliApiClient(mockOptions)
		} catch (error) {
			// Expected to fail until implementation
			apiClient = null
		}
	})

	afterEach(() => {
		vi.restoreAllMocks()
	})

	describe("SSE Stream Processing", () => {
		it("should parse single SSE event", async () => {
			if (apiClient) {
				const sseData =
					'data: {"candidates":[{"content":{"parts":[{"text":"Hello"}]},"finishReason":"STOP"}]}\n\n'

				const chunks = await apiClient.parseSSEStream(sseData)

				expect(chunks).toHaveLength(1)
				expect(chunks[0].candidates[0].content.parts[0].text).toBe("Hello")
				console.log("✅ Single SSE event parsing working")
			} else {
				console.log("❌ Single SSE event parsing not implemented")
				expect(true).toBe(true) // Will pass once implemented
			}
		})

		it("should parse multiple SSE events", async () => {
			if (apiClient) {
				const sseData = `data: {"candidates":[{"content":{"parts":[{"text":"Hello"}]}}]}

data: {"candidates":[{"content":{"parts":[{"text":" world"}]}}]}

data: {"candidates":[{"content":{"parts":[{"text":"!"}]},"finishReason":"STOP"}]}

`

				const chunks = await apiClient.parseSSEStream(sseData)

				expect(chunks).toHaveLength(3)
				expect(chunks[0].candidates[0].content.parts[0].text).toBe("Hello")
				expect(chunks[1].candidates[0].content.parts[0].text).toBe(" world")
				expect(chunks[2].candidates[0].content.parts[0].text).toBe("!")
				console.log("✅ Multiple SSE events parsing working")
			} else {
				console.log("❌ Multiple SSE events parsing not implemented")
				expect(true).toBe(true) // Will pass once implemented
			}
		})

		it("should handle incomplete JSON chunks", async () => {
			if (apiClient) {
				const incompleteChunks = [
					'data: {"candidates":[{"content":{"parts":[{"text":"Hel',
					'lo"}]},"finishReason":"STOP"}]}\n\n',
				]

				let result = []
				for (const chunk of incompleteChunks) {
					const parsed = await apiClient.parseSSEChunk(chunk)
					if (parsed) result.push(parsed)
				}

				expect(result).toHaveLength(1)
				expect(result[0].candidates[0].content.parts[0].text).toBe("Hello")
				console.log("✅ Incomplete JSON handling working")
			} else {
				console.log("❌ Incomplete JSON handling not implemented")
				expect(true).toBe(true) // Will pass once implemented
			}
		})

		it("should skip empty lines and comments", async () => {
			if (apiClient) {
				const sseData = `
: This is a comment
data: {"candidates":[{"content":{"parts":[{"text":"Hello"}]}}]}

: Another comment

data: {"candidates":[{"content":{"parts":[{"text":" world"}]}}]}

`

				const chunks = await apiClient.parseSSEStream(sseData)

				expect(chunks).toHaveLength(2)
				expect(chunks[0].candidates[0].content.parts[0].text).toBe("Hello")
				expect(chunks[1].candidates[0].content.parts[0].text).toBe(" world")
				console.log("✅ Empty lines and comments handling working")
			} else {
				console.log("❌ Empty lines and comments handling not implemented")
				expect(true).toBe(true) // Will pass once implemented
			}
		})

		it("should handle malformed SSE data gracefully", async () => {
			if (apiClient) {
				const malformedData = `data: invalid json
data: {"incomplete": 
data: {"candidates":[{"content":{"parts":[{"text":"Valid"}]}}]}

`

				const chunks = await apiClient.parseSSEStream(malformedData)

				// Should only parse the valid chunk
				expect(chunks).toHaveLength(1)
				expect(chunks[0].candidates[0].content.parts[0].text).toBe("Valid")
				console.log("✅ Malformed data handling working")
			} else {
				console.log("❌ Malformed data handling not implemented")
				expect(true).toBe(true) // Will pass once implemented
			}
		})
	})

	describe("ReadableStream Integration", () => {
		it("should process ReadableStream with SSE data", async () => {
			if (apiClient) {
				const mockChunks = [
					'data: {"candidates":[{"content":{"parts":[{"text":"Hello"}]}}]}\n\n',
					'data: {"candidates":[{"content":{"parts":[{"text":" world"}]}}]}\n\n',
					'data: {"candidates":[{"content":{"parts":[{"text":"!"}]},"finishReason":"STOP"}]}\n\n',
				]

				const mockReader = {
					read: vi
						.fn()
						.mockResolvedValueOnce({
							done: false,
							value: new TextEncoder().encode(mockChunks[0]),
						})
						.mockResolvedValueOnce({
							done: false,
							value: new TextEncoder().encode(mockChunks[1]),
						})
						.mockResolvedValueOnce({
							done: false,
							value: new TextEncoder().encode(mockChunks[2]),
						})
						.mockResolvedValueOnce({ done: true }),
					releaseLock: vi.fn(),
				}

				const mockStream = {
					getReader: () => mockReader,
				}

				const chunks = []
				for await (const chunk of apiClient.processSSEStream(mockStream)) {
					chunks.push(chunk)
				}

				expect(chunks).toHaveLength(3)
				expect(chunks[0].candidates[0].content.parts[0].text).toBe("Hello")
				expect(chunks[2].finishReason).toBe("STOP")
				console.log("✅ ReadableStream processing working")
			} else {
				console.log("❌ ReadableStream processing not implemented")
				expect(true).toBe(true) // Will pass once implemented
			}
		})

		it("should handle stream errors gracefully", async () => {
			if (apiClient) {
				const mockReader = {
					read: vi
						.fn()
						.mockResolvedValueOnce({
							done: false,
							value: new TextEncoder().encode('data: {"valid":"chunk"}\n\n'),
						})
						.mockRejectedValueOnce(new Error("Stream error")),
					releaseLock: vi.fn(),
				}

				const mockStream = {
					getReader: () => mockReader,
				}

				await expect(async () => {
					const chunks = []
					for await (const chunk of apiClient.processSSEStream(mockStream)) {
						chunks.push(chunk)
					}
				}).rejects.toThrow("Stream error")

				expect(mockReader.releaseLock).toHaveBeenCalled()
				console.log("✅ Stream error handling working")
			} else {
				console.log("❌ Stream error handling not implemented")
				expect(true).toBe(true) // Will pass once implemented
			}
		})

		it("should handle stream cancellation", async () => {
			if (apiClient) {
				const mockReader = {
					read: vi
						.fn()
						.mockResolvedValueOnce({
							done: false,
							value: new TextEncoder().encode('data: {"chunk":1}\n\n'),
						})
						.mockResolvedValueOnce({
							done: false,
							value: new TextEncoder().encode('data: {"chunk":2}\n\n'),
						}),
					releaseLock: vi.fn(),
					cancel: vi.fn(),
				}

				const mockStream = {
					getReader: () => mockReader,
				}

				const chunks = []
				const iterator = apiClient.processSSEStream(mockStream)

				// Get first chunk
				const { value: chunk1 } = await iterator.next()
				chunks.push(chunk1)

				// Cancel the stream
				await iterator.return()

				expect(chunks).toHaveLength(1)
				expect(mockReader.releaseLock).toHaveBeenCalled()
				console.log("✅ Stream cancellation working")
			} else {
				console.log("❌ Stream cancellation not implemented")
				expect(true).toBe(true) // Will pass once implemented
			}
		})
	})

	describe("Buffer Management", () => {
		it("should buffer incomplete lines across chunks", async () => {
			if (apiClient) {
				const chunks = [
					'data: {"candidates":[{"content":{"parts":[{"text":"Hel',
					'lo"}]},"finishReason":"STOP"}]}\n\n',
				]

				const buffer = apiClient.createSSEBuffer()

				// Process first incomplete chunk
				let result1 = buffer.process(chunks[0])
				expect(result1).toHaveLength(0) // No complete events yet

				// Process second chunk that completes the event
				let result2 = buffer.process(chunks[1])
				expect(result2).toHaveLength(1)
				expect(result2[0].candidates[0].content.parts[0].text).toBe("Hello")

				console.log("✅ Line buffering working")
			} else {
				console.log("❌ Line buffering not implemented")
				expect(true).toBe(true) // Will pass once implemented
			}
		})

		it("should handle multiple events in single chunk", async () => {
			if (apiClient) {
				const chunk = `data: {"candidates":[{"content":{"parts":[{"text":"First"}]}}]}

data: {"candidates":[{"content":{"parts":[{"text":"Second"}]}}]}

data: {"candidates":[{"content":{"parts":[{"text":"Third"}]}}]}

`

				const buffer = apiClient.createSSEBuffer()
				const results = buffer.process(chunk)

				expect(results).toHaveLength(3)
				expect(results[0].candidates[0].content.parts[0].text).toBe("First")
				expect(results[1].candidates[0].content.parts[0].text).toBe("Second")
				expect(results[2].candidates[0].content.parts[0].text).toBe("Third")

				console.log("✅ Multiple events in chunk working")
			} else {
				console.log("❌ Multiple events in chunk not implemented")
				expect(true).toBe(true) // Will pass once implemented
			}
		})

		it("should clear buffer on stream end", async () => {
			if (apiClient) {
				const buffer = apiClient.createSSEBuffer()

				// Add some incomplete data
				buffer.process('data: {"incomplete":')

				// End the stream
				const finalResults = buffer.flush()

				// Should not return incomplete data
				expect(finalResults).toHaveLength(0)
				expect(buffer.isEmpty()).toBe(true)

				console.log("✅ Buffer clearing working")
			} else {
				console.log("❌ Buffer clearing not implemented")
				expect(true).toBe(true) // Will pass once implemented
			}
		})
	})

	describe("Event Type Handling", () => {
		it("should handle different SSE event types", async () => {
			if (apiClient) {
				const sseData = `event: message
data: {"candidates":[{"content":{"parts":[{"text":"Hello"}]}}]}

event: error
data: {"error":{"message":"Something went wrong"}}

event: done
data: [DONE]

`

				const events = await apiClient.parseSSEEvents(sseData)

				expect(events).toHaveLength(3)
				expect(events[0].type).toBe("message")
				expect(events[1].type).toBe("error")
				expect(events[2].type).toBe("done")

				console.log("✅ Event type handling working")
			} else {
				console.log("❌ Event type handling not implemented")
				expect(true).toBe(true) // Will pass once implemented
			}
		})

		it("should handle events with IDs", async () => {
			if (apiClient) {
				const sseData = `id: 1
data: {"candidates":[{"content":{"parts":[{"text":"First"}]}}]}

id: 2
data: {"candidates":[{"content":{"parts":[{"text":"Second"}]}}]}

`

				const events = await apiClient.parseSSEEvents(sseData)

				expect(events[0].id).toBe("1")
				expect(events[1].id).toBe("2")

				console.log("✅ Event ID handling working")
			} else {
				console.log("❌ Event ID handling not implemented")
				expect(true).toBe(true) // Will pass once implemented
			}
		})

		it("should handle retry directives", async () => {
			if (apiClient) {
				const sseData = `retry: 3000
data: {"candidates":[{"content":{"parts":[{"text":"Hello"}]}}]}

`

				const events = await apiClient.parseSSEEvents(sseData)

				expect(events[0].retry).toBe(3000)

				console.log("✅ Retry directive handling working")
			} else {
				console.log("❌ Retry directive handling not implemented")
				expect(true).toBe(true) // Will pass once implemented
			}
		})
	})

	describe("Error Handling", () => {
		it("should handle JSON parsing errors", async () => {
			if (apiClient) {
				const invalidJson = 'data: {"invalid": json}\n\n'

				const consoleSpy = vi.spyOn(console, "warn").mockImplementation(() => {})

				const chunks = await apiClient.parseSSEStream(invalidJson)

				expect(chunks).toHaveLength(0)
				expect(consoleSpy).toHaveBeenCalledWith(expect.stringContaining("Failed to parse SSE JSON"))

				console.log("✅ JSON parsing error handling working")
			} else {
				console.log("❌ JSON parsing error handling not implemented")
				expect(true).toBe(true) // Will pass once implemented
			}
		})

		it("should handle encoding errors", async () => {
			if (apiClient) {
				// Simulate invalid UTF-8 bytes
				const invalidBytes = new Uint8Array([0xff, 0xfe, 0xfd])

				const result = await apiClient.processSSEBytes(invalidBytes)

				// Should handle gracefully without crashing
				expect(result).toBeDefined()

				console.log("✅ Encoding error handling working")
			} else {
				console.log("❌ Encoding error handling not implemented")
				expect(true).toBe(true) // Will pass once implemented
			}
		})

		it("should handle oversized chunks", async () => {
			if (apiClient) {
				// Create a very large chunk
				const largeText = "x".repeat(1000000) // 1MB
				const largeChunk = `data: {"candidates":[{"content":{"parts":[{"text":"${largeText}"}]}}]}\n\n`

				await expect(apiClient.parseSSEStream(largeChunk)).rejects.toThrow("Chunk too large")

				console.log("✅ Oversized chunk handling working")
			} else {
				console.log("❌ Oversized chunk handling not implemented")
				expect(true).toBe(true) // Will pass once implemented
			}
		})
	})

	describe("Performance Optimization", () => {
		it("should efficiently process large streams", async () => {
			if (apiClient) {
				// Generate many small chunks
				const chunks = Array.from(
					{ length: 1000 },
					(_, i) => `data: {"candidates":[{"content":{"parts":[{"text":"Chunk ${i}"}]}}]}\n\n`,
				).join("")

				const startTime = Date.now()
				const results = await apiClient.parseSSEStream(chunks)
				const endTime = Date.now()

				expect(results).toHaveLength(1000)
				expect(endTime - startTime).toBeLessThan(1000) // Should process in under 1 second

				console.log("✅ Large stream processing performance working")
			} else {
				console.log("❌ Large stream processing performance not implemented")
				expect(true).toBe(true) // Will pass once implemented
			}
		})

		it("should use memory efficiently", async () => {
			if (apiClient) {
				const buffer = apiClient.createSSEBuffer()

				// Process many chunks and verify memory doesn't grow unbounded
				for (let i = 0; i < 100; i++) {
					buffer.process(`data: {"chunk":${i}}\n\n`)
				}

				// Buffer should not retain all processed data
				expect(buffer.getBufferSize()).toBeLessThan(1000)

				console.log("✅ Memory efficiency working")
			} else {
				console.log("❌ Memory efficiency not implemented")
				expect(true).toBe(true) // Will pass once implemented
			}
		})
	})
})

describe("Phase 3 SSE Parsing - Implementation Status", () => {
	it("should track implementation progress", () => {
		try {
			require("../../../../src/api/providers/g-cli/api-client")
			console.log("✅ Phase 3 SSE Parsing - IMPLEMENTED")
		} catch (error: any) {
			console.log("📋 Phase 3 SSE Parsing Status:")
			console.log("❌ src/api/providers/g-cli/api-client.ts - Not implemented")
			console.log("")
			console.log("📝 Required SSE Parsing:")
			console.log("   1. parseSSEStream() - Parse complete SSE data")
			console.log("   2. processSSEStream() - Handle ReadableStream")
			console.log("   3. createSSEBuffer() - Buffer incomplete chunks")
			console.log("   4. parseSSEEvents() - Handle event types and IDs")
			console.log("   5. Error handling for malformed data")
			console.log("")
			console.log("🔧 SSE Format Support:")
			console.log("   - data: JSON chunks")
			console.log("   - event: message types")
			console.log("   - id: event identifiers")
			console.log("   - retry: reconnection delays")
			console.log("   - Comments and empty lines")
			console.log("")
			console.log("🎯 Next Steps:")
			console.log("   - Run response_processing.test.ts")
			console.log("   - Run error_handling.test.ts")
			console.log("   - Run performance.test.ts")

			expect(error.message).toContain("Cannot find module")
		}
	})
})
